{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4ad99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/home/onyxia/work/Advanced-ML\")\n",
    "from data_loader import S3ParquetReader\n",
    "from config import USER\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models import transformer, train_model, CombinedLoss\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30993393",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5532f54",
   "metadata": {},
   "source": [
    "Config initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3276cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = f\"/{USER}/jane_street_data\"\n",
    "reader = S3ParquetReader(bucket=BUCKET)\n",
    "FILE_KEY_S3 = \"preprocessed.parquet/data_clean_symb_1.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db8f80bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 78)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>feature_37</th><th>feature_38</th><th>feature_40</th><th>feature_41</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>&hellip;</th><th>feature_52</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_0</th><th>responder_1</th><th>responder_2</th><th>responder_3</th><th>responder_4</th><th>responder_5</th><th>responder_6</th><th>responder_7</th><th>responder_8</th><th>feature_time_sin</th><th>feature_time_cos</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>35</td><td>1</td><td>3.889038</td><td>0.127298</td><td>0.339121</td><td>-0.045494</td><td>0.151473</td><td>-0.038995</td><td>-0.644192</td><td>-0.193971</td><td>-0.016662</td><td>-0.213108</td><td>-0.045016</td><td>0.014899</td><td>0.128033</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.397016</td><td>0.694868</td><td>0.812098</td><td>-0.128621</td><td>0.025559</td><td>0.018694</td><td>-0.006306</td><td>-1.706433</td><td>-0.490941</td><td>0.425017</td><td>0.281025</td><td>-0.134582</td><td>0.046605</td><td>&hellip;</td><td>-0.207253</td><td>-0.307967</td><td>0.381731</td><td>0.756464</td><td>0.058235</td><td>0.060041</td><td>-0.479444</td><td>-0.000608</td><td>0.0</td><td>-0.000122</td><td>0.085259</td><td>-0.324355</td><td>-0.097414</td><td>-0.296044</td><td>0.21344</td><td>-0.20025</td><td>-0.11987</td><td>-0.007101</td><td>-0.693186</td><td>-0.181427</td><td>0.073886</td><td>-0.062266</td><td>0.136151</td><td>0.110356</td><td>0.055748</td><td>-0.028266</td><td>0.36224</td><td>-0.376568</td><td>-0.086291</td><td>-0.392552</td><td>-0.267725</td><td>-0.112329</td><td>-1.233082</td><td>0.131704</td><td>-0.024239</td><td>0.225461</td><td>0.974252</td></tr><tr><td>0</td><td>36</td><td>1</td><td>3.889038</td><td>0.114208</td><td>-1.419921</td><td>-0.505525</td><td>-0.258195</td><td>0.017889</td><td>-0.254385</td><td>0.015691</td><td>-0.020583</td><td>-0.15111</td><td>-0.034961</td><td>-0.045215</td><td>-0.411787</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.037745</td><td>-0.824408</td><td>-0.312367</td><td>0.272155</td><td>0.041673</td><td>0.051002</td><td>0.101001</td><td>-0.172871</td><td>0.356697</td><td>0.43781</td><td>-0.243426</td><td>0.116691</td><td>0.21925</td><td>&hellip;</td><td>0.174336</td><td>-0.325709</td><td>-0.301785</td><td>-0.332396</td><td>0.651199</td><td>-0.103911</td><td>-0.210683</td><td>0.088785</td><td>0.0</td><td>-0.013245</td><td>-0.067586</td><td>0.22172</td><td>0.347892</td><td>0.511532</td><td>-0.214167</td><td>-0.045423</td><td>-0.048534</td><td>0.048807</td><td>-0.407794</td><td>0.008081</td><td>-0.071584</td><td>0.056597</td><td>0.01653</td><td>-0.049644</td><td>-0.023103</td><td>-0.0531</td><td>0.283566</td><td>-0.397785</td><td>0.041572</td><td>0.001317</td><td>-0.112683</td><td>0.419467</td><td>-0.578848</td><td>0.269364</td><td>0.459819</td><td>0.231787</td><td>0.972767</td></tr><tr><td>0</td><td>37</td><td>1</td><td>3.889038</td><td>0.118826</td><td>-1.293755</td><td>-0.809856</td><td>0.268584</td><td>-0.056675</td><td>-0.273341</td><td>-0.016404</td><td>0.010669</td><td>0.172457</td><td>0.011381</td><td>0.013246</td><td>-0.016248</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.571682</td><td>0.168574</td><td>-0.042331</td><td>-0.55658</td><td>0.175519</td><td>-0.052067</td><td>0.053939</td><td>0.109843</td><td>-0.055707</td><td>-0.214608</td><td>-0.026042</td><td>-0.180718</td><td>-0.171372</td><td>&hellip;</td><td>-1.097941</td><td>-0.294437</td><td>-0.104787</td><td>0.504722</td><td>-0.285762</td><td>0.140226</td><td>-0.521822</td><td>-0.46183</td><td>0.0</td><td>0.226184</td><td>-0.100162</td><td>-0.029472</td><td>0.037072</td><td>0.097566</td><td>0.061552</td><td>-0.136708</td><td>-0.029742</td><td>-0.047774</td><td>-0.150518</td><td>-0.287006</td><td>-0.000054</td><td>-0.048201</td><td>-0.093462</td><td>-0.015866</td><td>0.051347</td><td>0.055587</td><td>0.260547</td><td>-0.299865</td><td>0.239627</td><td>-0.019651</td><td>-0.194262</td><td>0.321798</td><td>-0.683034</td><td>0.027111</td><td>0.075722</td><td>0.238102</td><td>0.97124</td></tr><tr><td>0</td><td>38</td><td>1</td><td>3.889038</td><td>-0.216346</td><td>-0.021069</td><td>-0.425764</td><td>-0.005701</td><td>-0.010654</td><td>0.302838</td><td>0.000491</td><td>-0.017648</td><td>-0.036415</td><td>-0.008958</td><td>0.384812</td><td>0.49453</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.202302</td><td>0.395804</td><td>-0.512155</td><td>0.642004</td><td>0.414221</td><td>0.113961</td><td>-0.131998</td><td>-0.374575</td><td>0.206433</td><td>-0.445924</td><td>-0.518108</td><td>0.268771</td><td>0.069906</td><td>&hellip;</td><td>0.08609</td><td>-0.610097</td><td>0.137679</td><td>-0.198983</td><td>-0.754921</td><td>-0.294851</td><td>0.352242</td><td>0.049567</td><td>0.0</td><td>-0.023089</td><td>0.036929</td><td>-0.176699</td><td>-0.503255</td><td>-0.449954</td><td>-0.134894</td><td>0.050516</td><td>-0.089379</td><td>0.004014</td><td>-0.204778</td><td>-0.144482</td><td>-0.082102</td><td>-0.050271</td><td>0.020269</td><td>-0.008658</td><td>0.096835</td><td>-0.042524</td><td>0.423799</td><td>-0.195033</td><td>0.145029</td><td>-0.076218</td><td>-0.304814</td><td>0.098249</td><td>-0.606483</td><td>-0.01076</td><td>-0.134628</td><td>0.244408</td><td>0.969673</td></tr><tr><td>0</td><td>39</td><td>1</td><td>3.889038</td><td>-0.660073</td><td>2.168059</td><td>0.903407</td><td>-0.101644</td><td>0.133174</td><td>-0.212203</td><td>-0.217244</td><td>0.006182</td><td>-0.076704</td><td>-0.027879</td><td>0.249095</td><td>-0.431726</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.511043</td><td>-0.221639</td><td>-0.014473</td><td>-0.572408</td><td>-0.297749</td><td>-0.126506</td><td>-0.083542</td><td>0.180433</td><td>-0.245343</td><td>0.052368</td><td>0.051568</td><td>-0.067317</td><td>0.585641</td><td>&hellip;</td><td>0.422847</td><td>1.033209</td><td>-0.497286</td><td>-0.080836</td><td>0.111428</td><td>0.351126</td><td>0.692625</td><td>0.136429</td><td>0.0</td><td>-0.158061</td><td>0.19554</td><td>0.039516</td><td>0.159207</td><td>0.312143</td><td>0.071603</td><td>0.039128</td><td>-0.042775</td><td>-0.063419</td><td>0.105373</td><td>-0.419445</td><td>0.211242</td><td>0.070223</td><td>-0.057609</td><td>-0.028877</td><td>-0.147115</td><td>0.014544</td><td>0.245084</td><td>-0.368908</td><td>0.058499</td><td>-0.083503</td><td>-0.257635</td><td>-0.007915</td><td>-0.446952</td><td>0.085893</td><td>-0.124889</td><td>0.250703</td><td>0.968064</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 78)\n",
       "┌─────────┬─────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ date_id ┆ time_id ┆ symbol_id ┆ weight   ┆ … ┆ responder_ ┆ responder_ ┆ feature_ti ┆ feature_ti │\n",
       "│ ---     ┆ ---     ┆ ---       ┆ ---      ┆   ┆ 7          ┆ 8          ┆ me_sin     ┆ me_cos     │\n",
       "│ i16     ┆ i16     ┆ i8        ┆ f32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│         ┆         ┆           ┆          ┆   ┆ f32        ┆ f32        ┆ f64        ┆ f64        │\n",
       "╞═════════╪═════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 0       ┆ 35      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.131704   ┆ -0.024239  ┆ 0.225461   ┆ 0.974252   │\n",
       "│ 0       ┆ 36      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.269364   ┆ 0.459819   ┆ 0.231787   ┆ 0.972767   │\n",
       "│ 0       ┆ 37      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.027111   ┆ 0.075722   ┆ 0.238102   ┆ 0.97124    │\n",
       "│ 0       ┆ 38      ┆ 1         ┆ 3.889038 ┆ … ┆ -0.01076   ┆ -0.134628  ┆ 0.244408   ┆ 0.969673   │\n",
       "│ 0       ┆ 39      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.085893   ┆ -0.124889  ┆ 0.250703   ┆ 0.968064   │\n",
       "└─────────┴─────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = reader.read_parquet(FILE_KEY_S3)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfba77d",
   "metadata": {},
   "source": [
    "Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "621e189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"responder_6\"\n",
    "features = [col for col in data.columns if \"feature\" in col]\n",
    "\n",
    "X, y = data[features], data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796521a",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b743dee",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TimeSeriesDataset.__init__() got an unexpected keyword argument 'seq_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m     13\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.X[idx], \u001b[38;5;28mself\u001b[39m.y[idx]\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m dataset = \u001b[43mTimeSeriesDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m split_idx = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.8\u001b[39m * \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[32m     19\u001b[39m train_dataset = torch.utils.data.Subset(\n\u001b[32m     20\u001b[39m     dataset, \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, split_idx)\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: TimeSeriesDataset.__init__() got an unexpected keyword argument 'seq_len'"
     ]
    }
   ],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
    "        y = torch.tensor(y.to_numpy(), dtype=torch.float32)\n",
    "        if y.ndim == 1:\n",
    "            y = y.view(-1, 1)\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "        \n",
    "dataset = TimeSeriesDataset(X, y, seq_len=50)\n",
    "\n",
    "split_idx = int(0.8 * len(dataset))\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(\n",
    "    dataset, range(0, split_idx)\n",
    ")\n",
    "val_dataset = torch.utils.data.Subset(\n",
    "    dataset, range(split_idx, len(dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bdba697",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfeb621",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b53a3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.transformer\n",
    "importlib.reload(models.transformer)\n",
    "from models.transformer import TimeSeriesDataset, TimeSeriesTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee0c26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeSeriesTransformer(\n",
    "    n_features=X.shape[1],\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    "    d_ff=256\n",
    ").to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-2,\n",
    "    weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37740967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30a065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [09:27<4:34:12, 567.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train MSE: 0.461364 | Val MSE: 0.526995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [18:58<4:25:41, 569.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train MSE: 0.461325 | Val MSE: 0.523426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [28:39<4:18:41, 574.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train MSE: 0.461362 | Val MSE: 0.523365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [38:18<4:09:49, 576.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train MSE: 0.461323 | Val MSE: 0.524880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [48:04<4:01:37, 579.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train MSE: 0.461428 | Val MSE: 0.523622\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(1, N_EPOCHS + 1)):\n",
    "    train_loss = train_one_epoch(\n",
    "        model, train_data_loader, optimizer, criterion, device\n",
    "    )\n",
    "\n",
    "    val_loss = validate(\n",
    "        model, val_data_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train MSE: {train_loss:.6f} | \"\n",
    "        f\"Val MSE: {val_loss:.6f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ff8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
