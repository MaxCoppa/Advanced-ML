{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4ad99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/home/onyxia/work/Advanced-ML\")\n",
    "from data_loader import S3ParquetReader\n",
    "from config import USER\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models import AutoEncoder, train_model, CombinedLoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30993393",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5532f54",
   "metadata": {},
   "source": [
    "Config initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3276cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = f\"/{USER}/jane_street_data\"\n",
    "reader = S3ParquetReader(bucket=BUCKET)\n",
    "FILE_KEY_S3 = \"preprocessed.parquet/data_clean_symb_1.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8f80bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 78)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>feature_37</th><th>feature_38</th><th>feature_40</th><th>feature_41</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>&hellip;</th><th>feature_52</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_0</th><th>responder_1</th><th>responder_2</th><th>responder_3</th><th>responder_4</th><th>responder_5</th><th>responder_6</th><th>responder_7</th><th>responder_8</th><th>feature_time_sin</th><th>feature_time_cos</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>35</td><td>1</td><td>3.889038</td><td>0.127298</td><td>0.339121</td><td>-0.045494</td><td>0.151473</td><td>-0.038995</td><td>-0.644192</td><td>-0.193971</td><td>-0.016662</td><td>-0.213108</td><td>-0.045016</td><td>0.014899</td><td>0.128033</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.397016</td><td>0.694868</td><td>0.812098</td><td>-0.128621</td><td>0.025559</td><td>0.018694</td><td>-0.006306</td><td>-1.706433</td><td>-0.490941</td><td>0.425017</td><td>0.281025</td><td>-0.134582</td><td>0.046605</td><td>&hellip;</td><td>-0.207253</td><td>-0.307967</td><td>0.381731</td><td>0.756464</td><td>0.058235</td><td>0.060041</td><td>-0.479444</td><td>-0.000608</td><td>0.0</td><td>-0.000122</td><td>0.085259</td><td>-0.324355</td><td>-0.097414</td><td>-0.296044</td><td>0.21344</td><td>-0.20025</td><td>-0.11987</td><td>-0.007101</td><td>-0.693186</td><td>-0.181427</td><td>0.073886</td><td>-0.062266</td><td>0.136151</td><td>0.110356</td><td>0.055748</td><td>-0.028266</td><td>0.36224</td><td>-0.376568</td><td>-0.086291</td><td>-0.392552</td><td>-0.267725</td><td>-0.112329</td><td>-1.233082</td><td>0.131704</td><td>-0.024239</td><td>0.225461</td><td>0.974252</td></tr><tr><td>0</td><td>36</td><td>1</td><td>3.889038</td><td>0.114208</td><td>-1.419921</td><td>-0.505525</td><td>-0.258195</td><td>0.017889</td><td>-0.254385</td><td>0.015691</td><td>-0.020583</td><td>-0.15111</td><td>-0.034961</td><td>-0.045215</td><td>-0.411787</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.037745</td><td>-0.824408</td><td>-0.312367</td><td>0.272155</td><td>0.041673</td><td>0.051002</td><td>0.101001</td><td>-0.172871</td><td>0.356697</td><td>0.43781</td><td>-0.243426</td><td>0.116691</td><td>0.21925</td><td>&hellip;</td><td>0.174336</td><td>-0.325709</td><td>-0.301785</td><td>-0.332396</td><td>0.651199</td><td>-0.103911</td><td>-0.210683</td><td>0.088785</td><td>0.0</td><td>-0.013245</td><td>-0.067586</td><td>0.22172</td><td>0.347892</td><td>0.511532</td><td>-0.214167</td><td>-0.045423</td><td>-0.048534</td><td>0.048807</td><td>-0.407794</td><td>0.008081</td><td>-0.071584</td><td>0.056597</td><td>0.01653</td><td>-0.049644</td><td>-0.023103</td><td>-0.0531</td><td>0.283566</td><td>-0.397785</td><td>0.041572</td><td>0.001317</td><td>-0.112683</td><td>0.419467</td><td>-0.578848</td><td>0.269364</td><td>0.459819</td><td>0.231787</td><td>0.972767</td></tr><tr><td>0</td><td>37</td><td>1</td><td>3.889038</td><td>0.118826</td><td>-1.293755</td><td>-0.809856</td><td>0.268584</td><td>-0.056675</td><td>-0.273341</td><td>-0.016404</td><td>0.010669</td><td>0.172457</td><td>0.011381</td><td>0.013246</td><td>-0.016248</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.571682</td><td>0.168574</td><td>-0.042331</td><td>-0.55658</td><td>0.175519</td><td>-0.052067</td><td>0.053939</td><td>0.109843</td><td>-0.055707</td><td>-0.214608</td><td>-0.026042</td><td>-0.180718</td><td>-0.171372</td><td>&hellip;</td><td>-1.097941</td><td>-0.294437</td><td>-0.104787</td><td>0.504722</td><td>-0.285762</td><td>0.140226</td><td>-0.521822</td><td>-0.46183</td><td>0.0</td><td>0.226184</td><td>-0.100162</td><td>-0.029472</td><td>0.037072</td><td>0.097566</td><td>0.061552</td><td>-0.136708</td><td>-0.029742</td><td>-0.047774</td><td>-0.150518</td><td>-0.287006</td><td>-0.000054</td><td>-0.048201</td><td>-0.093462</td><td>-0.015866</td><td>0.051347</td><td>0.055587</td><td>0.260547</td><td>-0.299865</td><td>0.239627</td><td>-0.019651</td><td>-0.194262</td><td>0.321798</td><td>-0.683034</td><td>0.027111</td><td>0.075722</td><td>0.238102</td><td>0.97124</td></tr><tr><td>0</td><td>38</td><td>1</td><td>3.889038</td><td>-0.216346</td><td>-0.021069</td><td>-0.425764</td><td>-0.005701</td><td>-0.010654</td><td>0.302838</td><td>0.000491</td><td>-0.017648</td><td>-0.036415</td><td>-0.008958</td><td>0.384812</td><td>0.49453</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.202302</td><td>0.395804</td><td>-0.512155</td><td>0.642004</td><td>0.414221</td><td>0.113961</td><td>-0.131998</td><td>-0.374575</td><td>0.206433</td><td>-0.445924</td><td>-0.518108</td><td>0.268771</td><td>0.069906</td><td>&hellip;</td><td>0.08609</td><td>-0.610097</td><td>0.137679</td><td>-0.198983</td><td>-0.754921</td><td>-0.294851</td><td>0.352242</td><td>0.049567</td><td>0.0</td><td>-0.023089</td><td>0.036929</td><td>-0.176699</td><td>-0.503255</td><td>-0.449954</td><td>-0.134894</td><td>0.050516</td><td>-0.089379</td><td>0.004014</td><td>-0.204778</td><td>-0.144482</td><td>-0.082102</td><td>-0.050271</td><td>0.020269</td><td>-0.008658</td><td>0.096835</td><td>-0.042524</td><td>0.423799</td><td>-0.195033</td><td>0.145029</td><td>-0.076218</td><td>-0.304814</td><td>0.098249</td><td>-0.606483</td><td>-0.01076</td><td>-0.134628</td><td>0.244408</td><td>0.969673</td></tr><tr><td>0</td><td>39</td><td>1</td><td>3.889038</td><td>-0.660073</td><td>2.168059</td><td>0.903407</td><td>-0.101644</td><td>0.133174</td><td>-0.212203</td><td>-0.217244</td><td>0.006182</td><td>-0.076704</td><td>-0.027879</td><td>0.249095</td><td>-0.431726</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.511043</td><td>-0.221639</td><td>-0.014473</td><td>-0.572408</td><td>-0.297749</td><td>-0.126506</td><td>-0.083542</td><td>0.180433</td><td>-0.245343</td><td>0.052368</td><td>0.051568</td><td>-0.067317</td><td>0.585641</td><td>&hellip;</td><td>0.422847</td><td>1.033209</td><td>-0.497286</td><td>-0.080836</td><td>0.111428</td><td>0.351126</td><td>0.692625</td><td>0.136429</td><td>0.0</td><td>-0.158061</td><td>0.19554</td><td>0.039516</td><td>0.159207</td><td>0.312143</td><td>0.071603</td><td>0.039128</td><td>-0.042775</td><td>-0.063419</td><td>0.105373</td><td>-0.419445</td><td>0.211242</td><td>0.070223</td><td>-0.057609</td><td>-0.028877</td><td>-0.147115</td><td>0.014544</td><td>0.245084</td><td>-0.368908</td><td>0.058499</td><td>-0.083503</td><td>-0.257635</td><td>-0.007915</td><td>-0.446952</td><td>0.085893</td><td>-0.124889</td><td>0.250703</td><td>0.968064</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 78)\n",
       "┌─────────┬─────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ date_id ┆ time_id ┆ symbol_id ┆ weight   ┆ … ┆ responder_ ┆ responder_ ┆ feature_ti ┆ feature_ti │\n",
       "│ ---     ┆ ---     ┆ ---       ┆ ---      ┆   ┆ 7          ┆ 8          ┆ me_sin     ┆ me_cos     │\n",
       "│ i16     ┆ i16     ┆ i8        ┆ f32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│         ┆         ┆           ┆          ┆   ┆ f32        ┆ f32        ┆ f64        ┆ f64        │\n",
       "╞═════════╪═════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 0       ┆ 35      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.131704   ┆ -0.024239  ┆ 0.225461   ┆ 0.974252   │\n",
       "│ 0       ┆ 36      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.269364   ┆ 0.459819   ┆ 0.231787   ┆ 0.972767   │\n",
       "│ 0       ┆ 37      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.027111   ┆ 0.075722   ┆ 0.238102   ┆ 0.97124    │\n",
       "│ 0       ┆ 38      ┆ 1         ┆ 3.889038 ┆ … ┆ -0.01076   ┆ -0.134628  ┆ 0.244408   ┆ 0.969673   │\n",
       "│ 0       ┆ 39      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.085893   ┆ -0.124889  ┆ 0.250703   ┆ 0.968064   │\n",
       "└─────────┴─────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = reader.read_parquet(FILE_KEY_S3)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfba77d",
   "metadata": {},
   "source": [
    "Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621e189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"responder_6\"\n",
    "features = [col for col in data.columns if \"feature\" in col]\n",
    "\n",
    "X, y = data[features], data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796521a",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b743dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.height\n",
    "n_train = int(0.001 * n)\n",
    "X_train = X.slice(0, n_train)\n",
    "y_train = y.slice(0, n_train)\n",
    "\n",
    "X_val = X.slice(n_train)\n",
    "y_val = y.slice(n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bdba697",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(X, y, seq_len=50)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TimeSeriesDataset(X, y, seq_len=50)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfeb621",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53a3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.transformer\n",
    "importlib.reload(models.transformer)\n",
    "from models.transformer import TimeSeriesDataset, TimeSeriesTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0c26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alpha = 1.0\n",
    "beta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd6ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "criterion = CombinedLoss(alpha=alpha, beta=beta)\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5a38150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m model = TimeSeriesTransformer(n_features=X_train.shape[\u001b[32m1\u001b[39m], d_model=\u001b[32m32\u001b[39m, num_heads=\u001b[32m4\u001b[39m, d_ff=\u001b[32m64\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/Advanced-ML/models/train_model.py:42\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, device, n_epochs, title)\u001b[39m\n\u001b[32m     39\u001b[39m yb = yb.to(device)\n\u001b[32m     40\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m _, x_hat, y_hat = model(xb)\n\u001b[32m     44\u001b[39m loss = criterion(x_hat, xb, y_hat, yb)\n\u001b[32m     45\u001b[39m loss.backward()\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "model = TimeSeriesTransformer(n_features=X_train.shape[1], d_model=32, num_heads=4, d_ff=64)\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_data_loader,\n",
    "    val_loader=val_data_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    n_epochs=n_epochs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7bb5ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformer(\n",
       "  (input_projection): Linear(in_features=65, out_features=128, bias=True)\n",
       "  (pos_encoding): PositionalEncoding()\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc_out): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37740967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
