{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e730145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append(\"/home/onyxia/work/Advanced-ML\")\n",
    "from data_loader import S3ParquetReader\n",
    "from config import USER\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models import train_model, CombinedLoss\n",
    "from models.advanced_autoencoders import AutoEncoder\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee5e0a",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e549dd",
   "metadata": {},
   "source": [
    "Config initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77c2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = f\"/{USER}/jane_street_data\"\n",
    "reader = S3ParquetReader(bucket=BUCKET)\n",
    "FILE_KEY_S3 = \"preprocessed.parquet/data_clean_symb_1.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64f8f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 79)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>feature_37</th><th>feature_38</th><th>feature_40</th><th>feature_41</th><th>feature_43</th><th>&hellip;</th><th>feature_49</th><th>feature_51</th><th>feature_52</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_0</th><th>responder_1</th><th>responder_2</th><th>responder_3</th><th>responder_4</th><th>responder_5</th><th>responder_6</th><th>responder_7</th><th>responder_8</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>34</td><td>1</td><td>3.889038</td><td>1.509601</td><td>0.885045</td><td>2.831856</td><td>-1.201967</td><td>11</td><td>7</td><td>76</td><td>-0.271028</td><td>0.695742</td><td>0.794157</td><td>-0.038239</td><td>0.045858</td><td>0.030772</td><td>-0.900359</td><td>-0.382682</td><td>0.91013</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>0.586801</td><td>0.250828</td><td>0.294883</td><td>0.521403</td><td>-0.682683</td><td>-0.239552</td><td>-0.460341</td><td>1.955693</td><td>1.485422</td><td>-0.253407</td><td>&hellip;</td><td>1.380354</td><td>1.116463</td><td>1.92235</td><td>0.375684</td><td>-1.258121</td><td>-0.705236</td><td>0.748627</td><td>0.643394</td><td>0.627821</td><td>1.411739</td><td>-1.36224</td><td>0.414762</td><td>0.683652</td><td>0.896076</td><td>-1.06081</td><td>-0.636584</td><td>-0.423285</td><td>0.055839</td><td>0.424335</td><td>-0.108809</td><td>1.035421</td><td>1.629745</td><td>-0.407497</td><td>-0.345388</td><td>-0.342097</td><td>-0.281208</td><td>-0.406524</td><td>-0.258637</td><td>0.573992</td><td>-0.319932</td><td>-0.335376</td><td>-0.21128</td><td>-0.279558</td><td>-0.434355</td><td>-1.220439</td><td>0.214211</td><td>-0.257941</td></tr><tr><td>0</td><td>35</td><td>1</td><td>3.889038</td><td>1.636899</td><td>1.224167</td><td>2.786362</td><td>-1.050494</td><td>11</td><td>7</td><td>76</td><td>-0.310024</td><td>0.05155</td><td>0.600186</td><td>-0.054901</td><td>-0.167249</td><td>-0.014244</td><td>-0.885459</td><td>-0.254649</td><td>0.91013</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>0.189785</td><td>0.945696</td><td>1.106982</td><td>0.392782</td><td>-0.657124</td><td>-0.220858</td><td>-0.466647</td><td>0.24926</td><td>0.994481</td><td>0.17161</td><td>&hellip;</td><td>1.066112</td><td>-1.037891</td><td>1.715097</td><td>0.067716</td><td>-0.876391</td><td>0.051228</td><td>0.806862</td><td>0.703435</td><td>0.148378</td><td>1.411131</td><td>-1.36224</td><td>0.41464</td><td>0.768911</td><td>0.571721</td><td>-1.158224</td><td>-0.932629</td><td>-0.209845</td><td>-0.144411</td><td>0.304465</td><td>-0.11591</td><td>0.342235</td><td>1.448319</td><td>-0.333611</td><td>-0.407654</td><td>-0.205946</td><td>-0.170852</td><td>-0.350776</td><td>-0.286903</td><td>0.36224</td><td>-0.376568</td><td>-0.086291</td><td>-0.392552</td><td>-0.267725</td><td>-0.112329</td><td>-1.233082</td><td>0.131704</td><td>-0.024239</td></tr><tr><td>0</td><td>36</td><td>1</td><td>3.889038</td><td>1.751107</td><td>-0.195755</td><td>2.280836</td><td>-1.308689</td><td>11</td><td>7</td><td>76</td><td>-0.292135</td><td>-0.202836</td><td>0.615877</td><td>-0.075484</td><td>-0.318359</td><td>-0.049205</td><td>-0.930674</td><td>-0.666436</td><td>0.91013</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>0.15204</td><td>0.121289</td><td>0.794614</td><td>0.664937</td><td>-0.615451</td><td>-0.169856</td><td>-0.365646</td><td>0.076389</td><td>1.351177</td><td>0.60942</td><td>&hellip;</td><td>1.095427</td><td>-1.714377</td><td>1.889433</td><td>-0.257992</td><td>-1.178176</td><td>-0.281169</td><td>1.45806</td><td>0.599523</td><td>-0.062305</td><td>1.499916</td><td>-1.36224</td><td>0.401396</td><td>0.701324</td><td>0.793441</td><td>-0.810332</td><td>-0.421096</td><td>-0.424012</td><td>-0.189834</td><td>0.255931</td><td>-0.067103</td><td>-0.06556</td><td>1.456399</td><td>-0.405195</td><td>-0.351057</td><td>-0.189416</td><td>-0.220496</td><td>-0.373879</td><td>-0.340003</td><td>0.283566</td><td>-0.397785</td><td>0.041572</td><td>0.001317</td><td>-0.112683</td><td>0.419467</td><td>-0.578848</td><td>0.269364</td><td>0.459819</td></tr><tr><td>0</td><td>37</td><td>1</td><td>3.889038</td><td>1.869932</td><td>-1.48951</td><td>1.470981</td><td>-1.040105</td><td>11</td><td>7</td><td>76</td><td>-0.34881</td><td>-0.476177</td><td>0.599473</td><td>-0.064814</td><td>-0.145902</td><td>-0.037824</td><td>-0.917428</td><td>-0.682684</td><td>0.91013</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>0.723722</td><td>0.289863</td><td>0.752283</td><td>0.108357</td><td>-0.439932</td><td>-0.221922</td><td>-0.311707</td><td>0.186232</td><td>1.29547</td><td>0.394812</td><td>&hellip;</td><td>0.979125</td><td>1.078464</td><td>0.791492</td><td>-0.55243</td><td>-1.282962</td><td>0.223554</td><td>1.172299</td><td>0.73975</td><td>-0.584127</td><td>1.038086</td><td>-1.36224</td><td>0.627579</td><td>0.601162</td><td>0.763969</td><td>-0.77326</td><td>-0.32353</td><td>-0.36246</td><td>-0.326542</td><td>0.226188</td><td>-0.114877</td><td>-0.216078</td><td>1.169394</td><td>-0.405249</td><td>-0.399258</td><td>-0.282878</td><td>-0.236362</td><td>-0.322532</td><td>-0.284416</td><td>0.260547</td><td>-0.299865</td><td>0.239627</td><td>-0.019651</td><td>-0.194262</td><td>0.321798</td><td>-0.683034</td><td>0.027111</td><td>0.075722</td></tr><tr><td>0</td><td>38</td><td>1</td><td>3.889038</td><td>1.653586</td><td>-1.510579</td><td>1.045217</td><td>-1.045805</td><td>11</td><td>7</td><td>76</td><td>-0.359463</td><td>-0.173339</td><td>0.599964</td><td>-0.082462</td><td>-0.182317</td><td>-0.046782</td><td>-0.532617</td><td>-0.188155</td><td>0.91013</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>0.52142</td><td>0.685667</td><td>0.240129</td><td>0.750362</td><td>-0.025711</td><td>-0.107961</td><td>-0.443705</td><td>-0.188343</td><td>1.501904</td><td>-0.051112</td><td>&hellip;</td><td>0.712261</td><td>0.803482</td><td>0.877582</td><td>-1.162526</td><td>-1.145284</td><td>0.024571</td><td>0.417377</td><td>0.444899</td><td>-0.231885</td><td>1.087653</td><td>-1.36224</td><td>0.60449</td><td>0.638092</td><td>0.58727</td><td>-1.276514</td><td>-0.773484</td><td>-0.497354</td><td>-0.276027</td><td>0.13681</td><td>-0.110864</td><td>-0.420856</td><td>1.024912</td><td>-0.48735</td><td>-0.449529</td><td>-0.262609</td><td>-0.24502</td><td>-0.225697</td><td>-0.326941</td><td>0.423799</td><td>-0.195033</td><td>0.145029</td><td>-0.076218</td><td>-0.304814</td><td>0.098249</td><td>-0.606483</td><td>-0.01076</td><td>-0.134628</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 79)\n",
       "┌─────────┬─────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ date_id ┆ time_id ┆ symbol_id ┆ weight   ┆ … ┆ responder_ ┆ responder_ ┆ responder_ ┆ responder_ │\n",
       "│ ---     ┆ ---     ┆ ---       ┆ ---      ┆   ┆ 5          ┆ 6          ┆ 7          ┆ 8          │\n",
       "│ i16     ┆ i16     ┆ i8        ┆ f32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│         ┆         ┆           ┆          ┆   ┆ f32        ┆ f32        ┆ f32        ┆ f32        │\n",
       "╞═════════╪═════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 0       ┆ 34      ┆ 1         ┆ 3.889038 ┆ … ┆ -0.434355  ┆ -1.220439  ┆ 0.214211   ┆ -0.257941  │\n",
       "│ 0       ┆ 35      ┆ 1         ┆ 3.889038 ┆ … ┆ -0.112329  ┆ -1.233082  ┆ 0.131704   ┆ -0.024239  │\n",
       "│ 0       ┆ 36      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.419467   ┆ -0.578848  ┆ 0.269364   ┆ 0.459819   │\n",
       "│ 0       ┆ 37      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.321798   ┆ -0.683034  ┆ 0.027111   ┆ 0.075722   │\n",
       "│ 0       ┆ 38      ┆ 1         ┆ 3.889038 ┆ … ┆ 0.098249   ┆ -0.606483  ┆ -0.01076   ┆ -0.134628  │\n",
       "└─────────┴─────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = reader.read_parquet(FILE_KEY_S3)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be2938",
   "metadata": {},
   "source": [
    "Ensure sorted by time_id to create batches not leaked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955b4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort(by=\"time_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7393b",
   "metadata": {},
   "source": [
    "Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1d1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"responder_6\"\n",
    "features = [col for col in data.columns if \"feature\" in col]\n",
    "\n",
    "X, y = data[features], data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a009106",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bea784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.height\n",
    "n_train = int(0.8 * n)\n",
    "X_train = X.slice(0, n_train)\n",
    "y_train = y.slice(0, n_train)\n",
    "\n",
    "X_val = X.slice(n_train)\n",
    "y_val = y.slice(n_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465e69c",
   "metadata": {},
   "source": [
    "Data Wraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a26d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
    "        y = torch.tensor(y.to_numpy(), dtype=torch.float32)\n",
    "        if y.ndim == 1:\n",
    "            y = y.view(-1, 1)\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d326abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "val_dataset = TimeSeriesDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ab6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "    train_dataset, batch_size=2048, shuffle=False, num_workers=8\n",
    ")\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bad88194",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "device = torch.device(\"cuda\")\n",
    "alpha = 1.0\n",
    "beta = 1.0\n",
    "n_epochs = 30\n",
    "\n",
    "n_feat = len(features)\n",
    "architectures_var_latent = {\n",
    "    # ----------------------------------------------------------------------\n",
    "    \"Archi_A_L8_Profonde\": {\n",
    "        \"description\": \"Forte compression (n_latent=8) + architecture profonde.\",\n",
    "        \"n_latent\": 8,\n",
    "        # Les tailles de couches sont conservées de l'Archi 1, seule n_latent change le nombre de paramètres\n",
    "        \"encoder_hidden\": [128, 64, 32, 16],\n",
    "        \"decoder_hidden\": [16, 32, 64, 128],\n",
    "        \"head_hidden\": [4, 2] # Le head est adapté à une entrée plus petite\n",
    "    },\n",
    "    # ----------------------------------------------------------------------\n",
    "    \"Archi_B_L32_Large\": {\n",
    "        \"description\": \"Faible compression (n_latent=32) + architecture large.\",\n",
    "        \"n_latent\": 32,\n",
    "        # Les tailles de couches sont conservées de l'Archi 2\n",
    "        \"encoder_hidden\": [160, 96, 64],\n",
    "        \"decoder_hidden\": [64, 96, 160],\n",
    "        \"head_hidden\": [32, 16] # Le head est adapté à une entrée plus grande\n",
    "    },\n",
    "    # ----------------------------------------------------------------------\n",
    "    \"Archi_C_L24_Hybride\": {\n",
    "        \"description\": \"Compression modérée (n_latent=24) + architecture hybride (profonde et large).\",\n",
    "        \"n_latent\": 24,\n",
    "        # Les tailles de couches sont conservées de l'Archi 3\n",
    "        \"encoder_hidden\": [256, 128, 64, 32],\n",
    "        \"decoder_hidden\": [32, 64, 128, 256],\n",
    "        \"head_hidden\": [24, 12, 6] # Le head est adapté à une entrée modérée\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16646549",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f2d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Lancement des entraînements par architecture et dimension latente ---\n",
      "\n",
      " Entraînement de l'architecture : Archi_A_L8_Profonde (n_latent=8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:12<05:59, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss=2756.729 | R2_rec_train=-3.2929 | R2_rec_val=0.1958 | R2_sup_train=-0.0227 | R2_sup_val=-0.0012\n"
     ]
    }
   ],
   "source": [
    "# Hyperparamètres fixés pour l'ensemble des tests\n",
    "# Note: Ces listes doivent être assez longues pour couvrir l'architecture la plus profonde (4 couches)\n",
    "activations = (nn.LeakyReLU, nn.LeakyReLU, nn.LeakyReLU)\n",
    "dropout_ps = (0, 0, 0.3)  # Légère régularisation ajoutée pour les grands modèles\n",
    "use_bns = (True, True, True)\n",
    "\n",
    "# Dictionnaire pour stocker tous les résultats\n",
    "all_results = {}\n",
    "\n",
    "print(\"--- Lancement des entraînements par architecture et dimension latente ---\")\n",
    "\n",
    "# Boucle principale sur les architectures\n",
    "for name, config in architectures_var_latent.items():\n",
    "    # Extraction de la dimension latente spécifique pour ce test\n",
    "    current_n_latent = config[\"n_latent\"]\n",
    "    \n",
    "    print(f\"\\n Entraînement de l'architecture : {name} (n_latent={current_n_latent})\")\n",
    "\n",
    "    # 1. Instanciation du Modèle\n",
    "    current_model = AutoEncoder(\n",
    "        n_feat=n_feat,\n",
    "        n_latent=current_n_latent, \n",
    "        encoder_hidden=config[\"encoder_hidden\"],\n",
    "        decoder_hidden=config[\"decoder_hidden\"],\n",
    "        head_hidden=config[\"head_hidden\"],\n",
    "        \n",
    "        # Slicing des hyperparamètres pour s'adapter à la profondeur du modèle\n",
    "        activations=activations[:len(config[\"encoder_hidden\"])],\n",
    "        dropout_ps=dropout_ps[:len(config[\"encoder_hidden\"])],\n",
    "        use_bns=use_bns[:len(config[\"encoder_hidden\"])]\n",
    "    )\n",
    "\n",
    "    current_model.to(device)\n",
    "\n",
    "    # 2. Instanciation de l'Optimiseur et du Critère\n",
    "    optimizer = Adam(current_model.parameters(), lr=lr)\n",
    "    criterion = CombinedLoss(alpha=alpha, beta=beta)\n",
    "\n",
    "    # 3. Entraînement\n",
    "    results = train_model(\n",
    "        model=current_model,\n",
    "        train_loader=train_data_loader,\n",
    "        val_loader=val_data_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        n_epochs=n_epochs,\n",
    "    )\n",
    "\n",
    "    # 4. Stockage des Résultats\n",
    "    all_results[name] = {\n",
    "        \"config\": config,\n",
    "        \"results\": results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc53ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
