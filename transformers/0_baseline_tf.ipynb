{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4ad99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/home/onyxia/work/Advanced-ML\")\n",
    "from data import S3ParquetReader\n",
    "from config import USER\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30993393",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3276cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from s3 storage\n",
    "BUCKET = f\"/{USER}/jane_street_data\"\n",
    "reader = S3ParquetReader(bucket=BUCKET)\n",
    "data = reader.read_parquet(\"preprocessed.parquet/data_clean_symb_1.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfba77d",
   "metadata": {},
   "source": [
    "# Split and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621e189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we pick responder_6 as the target (same target as the data challenge)\n",
    "target = \"responder_6\"\n",
    "features = [col for col in data.columns if \"feature\" in col]\n",
    "X, y = data[features], data[target]\n",
    "\n",
    "n = X.height\n",
    "n_train = int(0.8 * n)\n",
    "X_train = X.slice(0, n_train)\n",
    "y_train = y.slice(0, n_train)\n",
    "X_val = X.slice(n_train)\n",
    "y_val = y.slice(n_train)\n",
    "\n",
    "# # Scaling\n",
    "# scaler_x = StandardScaler()\n",
    "# scaler_y = StandardScaler()\n",
    "\n",
    "# # We use .to_numpy() for the scalers\n",
    "# x_train_np = scaler_x.fit_transform(X_train_raw.to_numpy())\n",
    "# # Important: y must be 2D for the scaler\n",
    "# y_train_np = scaler_y.fit_transform(y_train_raw.to_numpy().reshape(-1, 1))\n",
    "\n",
    "# x_val_np = scaler_x.transform(X_val_raw.to_numpy())\n",
    "# y_val_np = scaler_y.transform(y_val_raw.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6bf17d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70eefa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:20<12:04, 80.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | R² Train: 0.7992 | R² Val: 0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:38<10:34, 79.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | R² Train: 0.8402 | R² Val: 0.8522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:59<09:19, 79.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | R² Train: 0.8428 | R² Val: 0.8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [05:17<07:55, 79.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | R² Train: 0.8453 | R² Val: 0.8563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [06:37<06:37, 79.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | R² Train: 0.8467 | R² Val: 0.8343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [07:56<05:17, 79.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | R² Train: 0.8461 | R² Val: 0.8291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [09:18<04:00, 80.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | R² Train: 0.8478 | R² Val: 0.8134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [10:38<02:40, 80.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | R² Train: 0.8484 | R² Val: 0.8408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [11:58<01:19, 79.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | R² Train: 0.8485 | R² Val: 0.7691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:16<00:00, 79.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | R² Train: 0.8471 | R² Val: 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from models.transformers import TimeSeriesTransformer\n",
    "from models.transformers_utils import train_model\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "lr = 0.5e-2\n",
    "criterion = nn.MSELoss()\n",
    "n_epochs = 10\n",
    "batch_size = 2048\n",
    "device = \"cuda\"\n",
    "seq_len = 50\n",
    "d_model = 16\n",
    "num_heads = 4\n",
    "num_layers = 3\n",
    "d_ff = 16\n",
    "\n",
    "model = TimeSeriesTransformer(\n",
    "    n_features=n_features,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "r2_train_hist, r2_val_hist = train_model(\n",
    "    model, optimizer, criterion, \n",
    "    X_train, y_train, X_val, y_val,\n",
    "    epochs=n_epochs, batch_size=batch_size, seq_len = seq_len, device=device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viz_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
